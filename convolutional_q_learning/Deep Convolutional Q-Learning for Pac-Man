{"cells":[{"cell_type":"markdown","metadata":{"id":"EAiHVEoWHy_D"},"source":["# Deep Convolutional Q-Learning for Pac-Man"]},{"cell_type":"markdown","metadata":{"id":"tjO1aK3Ddjs5"},"source":["## Part 0 - Installing the required packages and importing the libraries"]},{"cell_type":"markdown","metadata":{"id":"NwdRB-ZLdrAV"},"source":["### Installing Gymnasium"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":101401,"status":"ok","timestamp":1726253435439,"user":{"displayName":"Paola Rocha","userId":"05398982671622189547"},"user_tz":360},"id":"dbnq3XpoKa_7","outputId":"97f7909f-d3e0-4e7d-edc7-a5a46ed14e01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gymnasium\n","  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy\u003e=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n","Collecting farama-notifications\u003e=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n","Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy\u003e=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.26.4)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n","Requirement already satisfied: typing-extensions\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (4.12.2)\n","Requirement already satisfied: farama-notifications\u003e=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n","Collecting shimmy\u003c1.0,\u003e=0.1.0 (from shimmy[atari]\u003c1.0,\u003e=0.1.0; extra == \"atari\"-\u003egymnasium[accept-rom-license,atari])\n","  Downloading Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n","Collecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari])\n","  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2-\u003eautorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari]) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2-\u003eautorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari]) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2-\u003eautorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari]) (4.66.5)\n","Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari])\n","  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting ale-py~=0.8.1 (from shimmy[atari]\u003c1.0,\u003e=0.1.0; extra == \"atari\"-\u003egymnasium[accept-rom-license,atari])\n","  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1-\u003eshimmy[atari]\u003c1.0,\u003e=0.1.0; extra == \"atari\"-\u003egymnasium[accept-rom-license,atari]) (6.4.5)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eautorom~=0.4.2-\u003eautorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari]) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eautorom~=0.4.2-\u003eautorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari]) (3.8)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eautorom~=0.4.2-\u003eautorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari]) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eautorom~=0.4.2-\u003eautorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"-\u003egymnasium[accept-rom-license,atari]) (2024.8.30)\n","Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n","Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446661 sha256=8a605d6fdc67129194f4a9a66296e6be4bafef9f0cdfe8c98d59bfc50f893203\n","  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: ale-py, shimmy, AutoROM.accept-rom-license, autorom\n","Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.4.2 shimmy-0.2.1\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  swig4.0\n","Suggested packages:\n","  swig-doc swig-examples swig4.0-examples swig4.0-doc\n","The following NEW packages will be installed:\n","  swig swig4.0\n","0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 1,116 kB of archives.\n","After this operation, 5,542 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n","Fetched 1,116 kB in 1s (772 kB/s)\n","Selecting previously unselected package swig4.0.\n","(Reading database ... 123597 files and directories currently installed.)\n","Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n","Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n","Selecting previously unselected package swig.\n","Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n","Unpacking swig (4.0.2-1ubuntu1) ...\n","Setting up swig4.0 (4.0.2-1ubuntu1) ...\n","Setting up swig (4.0.2-1ubuntu1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy\u003e=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.26.4)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n","Requirement already satisfied: typing-extensions\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.12.2)\n","Requirement already satisfied: farama-notifications\u003e=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n","Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n","  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pygame\u003e=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.6.0)\n","Collecting swig==4.* (from gymnasium[box2d])\n","  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.6 kB)\n","Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: box2d-py\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2349139 sha256=fef4a5aa554172aa44dd1c4f1609798dcfed217b89186cef6cfac6fcefb09ffb\n","  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n","Successfully built box2d-py\n","Installing collected packages: swig, box2d-py\n","Successfully installed box2d-py-2.3.5 swig-4.2.1\n"]}],"source":["!pip install gymnasium\n","!pip install \"gymnasium[atari, accept-rom-license]\"\n","!apt-get install -y swig\n","!pip install gymnasium[box2d]"]},{"cell_type":"markdown","metadata":{"id":"H-wes4LZdxdd"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9530,"status":"ok","timestamp":1726253444966,"user":{"displayName":"Paola Rocha","userId":"05398982671622189547"},"user_tz":360},"id":"Ho_25-9_9qnu"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from collections import deque\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Gymnasium environment\n","import gymnasium as gym"]},{"cell_type":"markdown","metadata":{"id":"m7wa0ft8e3M_"},"source":["## Part 1 - Building the AI"]},{"cell_type":"markdown","metadata":{"id":"dlYVpVdHe-i6"},"source":["### Creating the architecture of the Neural Network"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1726253444967,"user":{"displayName":"Paola Rocha","userId":"05398982671622189547"},"user_tz":360},"id":"5O8VxX5nnqB4","outputId":"ba046ec0-fe1e-447f-c4b2-ba585352a1c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["class Network(nn.Module):\n","  def __init__(self, action_size, seed = 42):\n","    super(Network, self).__init__()\n","    self.seed = torch.manual_seed(seed)\n","    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size = 8, stride = 4) # 3 channels, kernel: 8x8\n","    self.bn1 = nn.BatchNorm2d(32) # batch normalization operation\n","    self.conv2 = nn.Conv2d(32, 64, kernel_size = 4, stride = 2)\n","    self.bn2 = nn.BatchNorm2d(64) # batch normalization operation\n","    self.conv3 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1)\n","    self.bn3 = nn.BatchNorm2d(64) # batch normalization operation\n","    self.conv4 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1)\n","    self.bn4 = nn.BatchNorm2d(128) # batch normalization operation\n","    self.fc1 = nn.Linear(10 * 10 * 128, 512) # firts full connected layer\n","    self.fc2 = nn.Linear(512, 256)\n","    self.fc3 = nn.Linear(256, action_size)\n","\n","  def forward(self, state):\n","    x = F.relu(self.bn1(self.conv1(state)))\n","    x = F.relu(self.bn2(self.conv2(x)))\n","    x = F.relu(self.bn3(self.conv3(x)))\n","    x = F.relu(self.bn4(self.conv4(x)))\n","    x = x.view(x.size(0), -1) # Flatening: reshapes the tensor\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    return self.fc3(x)"]},{"cell_type":"markdown","metadata":{"id":"rUvCfE_mhwo2"},"source":["## Part 2 - Training the AI"]},{"cell_type":"markdown","metadata":{"id":"WWCDPF22lkwc"},"source":["### Setting up the environment"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":837,"status":"ok","timestamp":1726253445800,"user":{"displayName":"Paola Rocha","userId":"05398982671622189547"},"user_tz":360},"id":"ON25vZ9kozvD","outputId":"15f0c62c-43fd-4bfd-e49e-8e198fe2ccfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["State shape: (210, 160, 3)\n","State size: 210\n","Number of actions: 9\n"]}],"source":["env = gym.make('MsPacmanDeterministic-v4', full_action_space = False)\n","state_shape = env.observation_space.shape\n","state_size = env.observation_space.shape[0]\n","number_actions = env.action_space.n\n","print(\"State shape:\", state_shape)\n","print(\"State size:\", state_size)\n","print(\"Number of actions:\", number_actions)"]},{"cell_type":"markdown","metadata":{"id":"Bx6IdX3ciDqH"},"source":["### Initializing the hyperparameters"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1726253445801,"user":{"displayName":"Paola Rocha","userId":"05398982671622189547"},"user_tz":360},"id":"Nacfq04gqNmb","outputId":"54feb771-1c54-4d11-d121-1195703e6bd7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["learning_rate = 5e-4  # Experimental value\n","minibatch_size = 64  # Experimental value\n","discount_factor = 0.99  # gamma value"]},{"cell_type":"markdown","metadata":{"id":"U2bDShIEkA5V"},"source":["### Preprocessing the frames"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3410,"status":"ok","timestamp":1726253449204,"user":{"displayName":"Paola Rocha","userId":"05398982671622189547"},"user_tz":360},"id":"9f-46VpFrmQi"},"outputs":[],"source":["from PIL import Image\n","from torchvision import transforms\n","\n","def preprocess_frame(frame):\n","  frame = Image.fromarray(frame) # Transforms a vector to an Image object\n","  preprocess = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])\n","  return preprocess(frame).unsqueeze(0)"]},{"cell_type":"markdown","metadata":{"id":"imMdSO-HAWra"},"source":["### Implementing the DCQN class"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1726253449205,"user":{"displayName":"Paola Rocha","userId":"05398982671622189547"},"user_tz":360},"id":"P2pQzksQwCsy","outputId":"5330f278-e5a9-48c8-be6c-784c9a3f392d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["class Agent:\n","  def __init__(self, action_size) -\u003e None:\n","    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    self.action_size = action_size\n","    self.local_qnetwork = Network(action_size).to(self.device)\n","    self.target_qnetwork = Network(action_size).to(self.device)\n","    self.optimizer = optim.Adam(self.local_qnetwork.parameters(), lr = learning_rate)\n","    self.memory = deque(maxlen = 10000)\n","\n","  def step(self, state, action, reward, next_state, done):\n","    state = preprocess_frame(state)\n","    next_state = preprocess_frame(next_state)\n","    self.memory.append((state, action, reward, next_state, done))\n","    if len(self.memory) \u003e minibatch_size:\n","      experiences = random.sample(self.memory, k = minibatch_size)\n","      self.learn(experiences, discount_factor)\n","\n","  def act(self, state, epsilon = 0.):\n","    \"\"\"Epsilon-Greedy Action Selection policy.\n","\n","    By generating a random value and comparing it with\n","    epsilon value that allows to leave some room for\n","    exploration because some actions will be randomly\n","    selected (instead of always being predicted by the agent)\"\"\"\n","    state = preprocess_frame(state).to(self.device)\n","    self.local_qnetwork.eval()\n","\n","    # Checking we are not in training\n","    # i.e., we are predicting\n","    with torch.no_grad(): # make sure any gradient computation is disabled\n","      action_values = self.local_qnetwork(state)\n","\n","    self.local_qnetwork.train()\n","    if random.random() \u003e epsilon:\n","      return np.argmax(action_values.cpu().data.numpy())\n","    else:\n","      return random.choice(np.arange(self.action_size))\n","\n","  def learn(self, experiences, discount_factor):\n","    states, actions, rewards, next_states, dones = zip(*experiences) # experiences is a tuple\n","    states = torch.from_numpy(np.vstack(states)).float().to(self.device)\n","    actions = torch.from_numpy(np.vstack(actions)).long().to(self.device)\n","    rewards = torch.from_numpy(np.vstack(rewards)).float().to(self.device)\n","    next_states = torch.from_numpy(np.vstack(next_states)).float().to(self.device)\n","    dones = torch.from_numpy(np.vstack(dones).astype(np.uint8)).float().to(self.device)\n","\n","    # getting maximum predicted q values of the next stage\n","    next_q_target = self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n","    q_targets = rewards + (discount_factor * next_q_target * (1 - dones))\n","\n","    # expected q values for the locat network\n","    q_expected = self.local_qnetwork(states).gather(1, actions)\n","\n","    # Computing the loss\n","    loss = F.mse_loss(q_expected, q_targets)\n","\n","    # Backpropagate the loss\n","    self.optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Updating the parameters of the model\n","    self.optimizer.step()\n"]},{"cell_type":"markdown","metadata":{"id":"yUg95iBpAwII"},"source":["### Initializing the DCQN agent"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":530,"status":"ok","timestamp":1726253449732,"user":{"displayName":"Paola Rocha","userId":"05398982671622189547"},"user_tz":360},"id":"4L6RujN11XH5"},"outputs":[],"source":["agent = Agent(number_actions)"]},{"cell_type":"markdown","metadata":{"id":"CK6Zt_gNmHvm"},"source":["### Training the DCQN agent"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YG1Xb2FZ1h7l"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode 71\tAverage Score: 273.66"]}],"source":["# Hyperparameters\n","number_episodes = 2000\n","maximum_number_timesteps_per_episode = 10000\n","epsilon_starting_value = 1.0\n","epsilon_ending_value = 0.01\n","epsilon_decay_value = 0.995\n","epsilon = epsilon_starting_value\n","scores_on_100_episodes = deque(maxlen = 100)\n","\n","for episode in range(1, number_episodes + 1):\n","  # reset the environment to the initial state\n","  state, _ = env.reset()\n","  # Initialize the score\n","  score = 0\n","\n","  for t in range(0, maximum_number_timesteps_per_episode):\n","    # Select the action\n","    action = agent.act(state, epsilon)\n","    # Move and end in a new state, also get the reward\n","    next_state, reward, done, _, _ = env.step(action)\n","    # Training!\n","    agent.step(state, action, reward, next_state, done)\n","    state = next_state\n","    score += reward\n","    if done:\n","      break\n","\n","  # Updateing the scores after the episode\n","  scores_on_100_episodes.append(score)\n","  epsilon = max(epsilon_ending_value, epsilon_decay_value * epsilon)\n","\n","  # Printing dynamically the scores (reward)\n","  print(f'\\rEpisode {episode}\\tAverage Score: {round(np.mean(scores_on_100_episodes), 2)}', end = \"\")\n","  if episode % 100 == 0:\n","    print(f'\\rEpisode {episode}\\tAverage Score: {round(np.mean(scores_on_100_episodes), 2)}')\n","\n","  if np.mean(scores_on_100_episodes) \u003e= 500.0:\n","    print(f'\\n Environment solved in {episode - 100} episodes\\tAverage Score: {round(np.mean(scores_on_100_episodes), 2)}')\n","    torch.save(agent.local_qnetwork.state_dict(), \"checkpoint.pth\")\n","    break"]},{"cell_type":"markdown","metadata":{"id":"-0WhhBV8nQdf"},"source":["## Part 3 - Visualizing the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb9nVvU2Okhk"},"outputs":[],"source":["import glob\n","import io\n","import base64\n","import imageio\n","from IPython.display import HTML, display\n","from gym.wrappers.monitoring.video_recorder import VideoRecorder\n","\n","def show_video_of_model(agent, env_name):\n","    env = gym.make(env_name, render_mode='rgb_array')\n","    state, _ = env.reset()\n","    done = False\n","    frames = []\n","    while not done:\n","        frame = env.render()\n","        frames.append(frame)\n","        action = agent.act(state)\n","        state, reward, done, _, _ = env.step(action)\n","    env.close()\n","    imageio.mimsave('video.mp4', frames, fps=30)\n","\n","show_video_of_model(agent, 'MsPacmanDeterministic-v4')\n","\n","def show_video():\n","    mp4list = glob.glob('*.mp4')\n","    if len(mp4list) \u003e 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        display(HTML(data='''\u003cvideo alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\"\u003e\n","                \u003csource src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /\u003e\n","             \u003c/video\u003e'''.format(encoded.decode('ascii'))))\n","    else:\n","        print(\"Could not find video\")\n","\n","show_video()"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","name":"","provenance":[{"file_id":"1dz5dOAOesQTXsK26MX2GzhwngRE97spW","timestamp":1725828006507},{"file_id":"1nqb-KnVe1EsZF-03Iba7T3cZFsnVRl4H","timestamp":1695853702757}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}